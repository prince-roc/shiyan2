file:///c%3A/Users/luoyiyi/learngit/awesome.md {"mtime":1695369401465,"ctime":1695367934712,"size":708,"etag":"3b85snj2imq","orphaned":false,"typeId":""}
# awesome-remote-change-image
The project is currently under construction
### Papers
#### Lite Version
* [**ICIIF 2018**]  [Least Squares Twin Extreme Learning Machine for Pattern Classification](https://link.springer.com/chapter/10.1007/978-981-13-1966-2_50) *Amisha et al.*  [[paper]](https://link.springer.com/book/10.1007/978-981-13-1966-2)<br/>
* [**ScienceDirect 2001**]   [A Survey of Computer Vision-Based Human Motion Capture](https://www.sciencedirect.com/science/article/pii/S107731420090897X) *Thomas et al.*  [[paper]](https://www.sciencedirect.com/)<br/>
* [**ICIIF 2018**]  [A Statistical Approach to Texture Classification from Single Images](https://link.springer.com/article/10.1023/B:VISI.0000046589.39864.ee) *Manik et al.*  [[paper]](https://link.springer.com/)<br/>
*  [**IEEE 2000**]  [Twenty Years of Document Image Analysis in PAMI](https://ieeexplore.ieee.org/document/824820) *George Nagy.*  [[paper]](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34)<br/>
*  [**ICIIF 2018**]  [Least Squares Twin Extreme Learning Machine for Pattern Classification](https://link.springer.com/chapter/10.1007/978-981-13-1966-2_50) *Amisha et al.*  [[paper]](https://link.springer.com/book/10.1007/978-981-13-1966-2)<br/>
  *  [**NeurIPS 2022**]  [Learning Distinct and Representative Modes for Image Captioning](https://proceedings.neurips.cc/paper_files/paper/2022/hash/3d77c6dcc7f143aa2154e7f4d5e22d68-Abstract-Conference.html) *Chen et al.*  [[paper]](https://neurips.cc/)<br/> 
  *   [**ACM 2021**]  [Scene Graph with 3D Information for Change Captioning](https://dl.acm.org/doi/10.1145/3474085.3475712) *Liao et al.*  [[paper]](https://dl.acm.org/)<br/>
#### Full Version
| Paper info | Description |
|---|---|
| [Least Squares Twin Extreme Learning Machine for Pattern Classification](https://link.springer.com/chapter/10.1007/978-981-13-1966-2_50)<br/>*Rastogi, R. ; Bharti, A.*<br/>> South Asian University, New Delhi, 110021, Delhi, India<br/>> ICIIF 2018<br/>> `Extreme learning machine``Twin support vector machine``Classification``recognition`, <br/>> Cited by 2594 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/1.png" width="300"></div><br/>The paper proposes Least Squares Twin Extreme Learning Machine (LSTELM) for pattern classification . LSTELM formulation solves Extreme Learning Machine (ELM) problem in twin framework.
| [A Survey of Computer Vision-Based Human Motion Capture](https://www.sciencedirect.com/science/article/pii/S107731420090897X)<br/>*Thomas B. Moeslund and Erik Granum*<br/>> Laboratory of Computer Vision and Media Technology, Aalborg University, Niels Jernes Vej 14, Aalborg, 9220, Denmarkf1<br/>> ScienceDirect 2001<br/>> `initialization``tracking``pose estimation``Least squares`, <br/>> Cited by 6 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/2.1.png" width="300"></div><br/>The paper proposes a comprehensive survey of computer vision-based human motion capture literature from the past two decades is presented. The focus is on a general overview based on a taxonomy of system functionalities, broken down into four processes: initialization, tracking, pose estimation, and recognition.<br/> 
| [A Statistical Approach to Texture Classification from Single Images](https://link.springer.com/article/10.1023/B:VISI.0000046589.39864.ee)<br/>*Manik Varma / Andrew Zisserman*<br/>> Robotics Research Group, Department of Engineering Science, University of Oxford, Oxford, OX1 3PJ, UK<br/>> ICIIF 2018<br/>> `Extreme learning machine``Twin support vector machine``Classification``recognition`, <br/>> Cited by 2594 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/3.png" width="300"></div><br/>The paper proposes texture classification from single images obtained under unknown viewpoint and illumination. A statistical approach is developed where textures are modelled by the joint probability distribution of filter responses.
| [Twenty Years of Document Image Analysis in PAMI](https://ieeexplore.ieee.org/document/824820)<br/>*George Nagy*<br/>>  South Asian University, New Delhi, 110021, Delhi, India<br/>> IEEE 2000<br/>> ` Extreme learning machine``Twin support vector machine``Classification``Least squares`, <br/>> Cited by 6 | <div align="center"><img src="https://raw.githubusercontent.com/iOPENCap/awesome-change-caption/img-storage/4.png" width="300"></div><br/>The contributions to document image analysis of 99 papers published in the E E E Transactions on Pattern Anaiysis and Machine hteiligence (PAMI) are clustered, summarized, interpolated, interpreted, and tactfully evaluated.|
| [A Statistical Approach to Texture Classification from Single Images](https://link.springer.com/article/10.1023/B:VISI.0000046589.39864.ee)<br/>*Manik Varma / Andrew Zisserman*<br/>> Robotics Research Group, Department of Engineering Science, University of Oxford, Oxford, OX1 3PJ, UK<br/>> ICIIF 2018<br/>> `Extreme learning machine``Twin support vector machine``Classification``recognition`, <br/>> Cited by 2594 | <div align="center"><img src="https://github.com/iOPENCap/awesome-change-caption/blob/master/pic/paper5.png" width="300"></div><br/>The paper proposes Least Squares Twin Extreme Learning Machine (LSTELM) for pattern classification . LSTELM formulation solves Extreme Learning Machine (ELM) problem in twin framework.
<br/> |
| [Learning Distinct and Representative Modes for Image Captioning](https://proceedings.neurips.cc/paper_files/paper/2022/hash/3d77c6dcc7f143aa2154e7f4d5e22d68-Abstract-Conference.html)<br/>*Qi Chen, Chaorui Deng, Qi Wu*<br/>>  NeurIPS 2022<br/>> `Computer Science``Computer Vision and Pattern Recognition` <br/>> Cited by 1 | <div align="center"><img src="https://github.com/iOPENCap/awesome-change-caption/blob/master/pic/paper%206.jpg" width="300"></div><br/>Therefore, this article proposes a method of learning discrete control signals from training corpus. The author believes that each text corresponds to a mode, and the number of modes is a hyperparameter. Each mode in the training phase corresponds to a control signal in the testing phase. The embedded representation of all control signals constitutes the codebook.